---
layout: post
title:  "CMA"
date:   2018-12-18 14:33:30 +0800
categories: [HW]
excerpt: CMA.
tags:
  - Bus
---

> github: https://github.com/BiscuitOS/HardStack/tree/master/bus/CMA
>
> Email: BuddyZhang1 <buddy.zhang@aliyun.com>

# 目录

> 1. CMA 原理
>
> 2. Kernel 中使用 CMA 内存
>
> 3. 用户空间使用 CMA 内存
>
> 4. 超大 CMA 内存设置方法
>
> 5. 附录

----------------------------------------------------------

# CMA 原理

CMA（Contiguous Memory Allocator）是连续内存分配技术，是 Linux Kernel 内存管理
系统的扩展，目的在于解决视频播放（特别对于 4K 视频）需要预留大量连续内存导致运
行内存紧张的问题。连续内存分配器(CMA - Contiguous Memory Allocator) 是一个框架，
允许建立一个平台无关的配置，用于连续内存的管理。然后，设备所需内存都根据该配置
进行分配。这个框架的主要作用不是分配内存，而是解析和管理内存配置，以及作为在设
备驱动程序和可插拔的分配器之间的中间组件。因此，它是与任何内存分配方法和分配策
略没有依赖关系的。

从设备驱动角度看，任何事情都不应该被影响。因为 CMA 是被集成到 DMA 子系统，所以
以前调用 DMA API（例如dma_alloc_coherent()）的地方应该照常工作。事实上，设备驱
动永远不需要直接调用 CMA API，因为它是在页和页帧编号（PFNs）上操作而无关总线地
址和内核映射，并且也不提供维护缓存一致性的机制。获取更多信息，可以参考这两份有
用的文档。这两篇文档描述了DMA 提供的方法接口及使用用例。

> Documentation/DMA-API.txt
>
> Documentation/DMA-API-HOWTO.txt


## CMA 需求

在嵌入式设备中，很多设备都没有支持 scatter-getter 和 IO map，都需要连续内存块
的操作。如设备：摄像机，硬件视频解码器，编码器等。这些设备往往需要较大的内存缓
冲区（如：一个200万像素的高清帧摄像机，需要超过 6M 的内存），该 kmalloc 内存分
配机制对于这么大的内存是没有效果的。一些嵌入式设备对缓冲区有一些额外的要求，比
如：在含有多个内存 bank 的设备中，要求只能在特定的bank 中中分配内存；而还有一
些要定内存边界对齐的缓存区。近来，嵌入式设备有了较大的发展(特别是 V4L 领域)，
并且这些驱动都有自己的内存分配代码。它们众多的大多数都是采用 bootmem 分配方法。
CMA 框架企图采用统一的连续内存分配机制，并为这些设备驱动提供简单的API，而且是
可以定制化和模块化的。

## CMA 设计

CMA 主要设计目标是提供一个可定制的模块化框架，并且是可以配置的，以适应个别系统
的需要。配置指定的内存区域，然后将这些内存分配给制定的设备。这些内存区域可以共
享给多个设备驱动，也可以专门分配一个。这是通过以下方式实现的：

> 1. CMA 的核心不是处理内存分配和空闲空间管理。专用分配器是用来处理内存分配和
>    空闲内存管理的。因此，如果现有的解决方案不符合给定的系统，那么可以开发一
>    种新的算法，这种算饭可以很容易地插入到 CMA 框架中。所提出的解决方案中包括
>    一个最适算法(best-fit)的一个实现。
>
> 2. CMA 允许运行时配置即将分配的内存区域。内存区域都是经由命令行给出的，所以
>    可以很容易地改变它，而不需要重新编译内核。每个地区都有自己的大小，对齐标
>    准，起始地址（物理地址）和对应该内存区域的内存分配算法。这意味着同一时刻
>    可以有多中机制在运行，如果在一个平台上同时运行多个不同的设备，这些设备具
>    有不同的存储器使用特性，那么局可以匹配最好的算法。
>
> 3. 当设备请求内存时，设备必须“自我介绍”，即附带自己的信息以告知 CMA。这样 CMA
>    可以知道谁分配内存。这允许系统架构师来指定哪个移动设备应该使用哪些存储区。
>    设备也可以指定一个“类”内存区域，这使得系统更容易配置，进而一个单一的设备
>    可能使用来自不同内存区域的内存。例如，一个视频解码器驱动程序可能要分配一
>    些共享的缓冲区，那么从第一个 bank 中分配一些，再从第二个 bank 中分配一些，
>    可以获得尽可能高的内存吞吐量
>
> 4. 通过这套机制，我们可以做到不预留内存，这些内存平时是可用的，只有当需要的
>    时候才被分配给 Camera，HDMI 等设备。

## CMA 关键点

#### 如何保证内存被复用

CMA 通过在启动阶段预先保留内存。这些内存叫做 CMA 区域或 CMA 上下文，稍后返回给
伙伴系统从而可以被用作正常申请。如果要保留内存，则需要恰好在底层“memblock”分配
器初始化之后，及大量内存被占用之前调用，并在伙伴系统建立之前调用：

{% highlight ruby %}
void dma_contiguous_reserve(phys_addr_t limit)
{% endhighlight %}

#### 要理解 CMA 如何工作，需要了解一些迁移类型和页块的知识。

当从伙伴系统申请内存的时候，需要提供一个 gfp_mask 参数。不管其他事情，这个参数
指定了要申请内存的迁移类型。一个前一类型是 MIGRATE_MOVABLE。它背后的意思是在可
移动页面上的数据可以被迁移（或者移动，因此而命名），这对于磁盘缓存或者进程页面
来说很有效。为了使相同迁移类型的页面在一起，伙伴系统把页面组成“页面块”，每组都
有一个指定的迁移类型。分配器根据请求的类型在不同的页面块上分配页。如果尝试失
败，分配器会在其它页面块上分配并甚至修改页面块的迁移类型。这意味着一个不可移动
的页可能分配自一个 MIGRATE_MOVABLE 页面块，并导致该页面块的迁移类型改变。这不
是 CMA 想要的，所以它引入了一个 MIGRATE_CMA 类型，该类型又一个重要的属性：只有
可移动页可以从 MIGRATE_CMA 页面块种分配。那么，在启动期间，当 
dma_congiguous_reserve() 和 dma_declare_contiguous() 方法被调用的时候，CMA 在
memblock 中预留一部分 RAM，并在随后将其返还给伙伴系统，仅将其页面块的迁移类型
置为 MIGRATE_CMA。最终的结果是所有预留的页都在伙伴系统里，所以它们都可以用于可
移动页的分配。

在CMA分配的时候，dma_alloc_from_contiguous() 选择一个页范围并调用：

{% highlight ruby %}
int alloc_contig_range(unsigned long start, unsigned long end,unsigned migratetype);
{% endhighlight %}

start 和 end 参数指定了目标内存的页框个数（或PFN范围）。最后一个参数 
migratetype 指定了潜在的迁移类型；在 CMA 的情况下，这个参数就是 MIGRATE_CMA。
这个函数所做的第一件事是将包含 (start, end) 范围内的页面块标记为
MIGRATE_ISOLATE。伙伴系统不会去触动这种类型的页面块。改变迁移类型不会魔法般地
释放页面，因此接下来需要调用__alloc_conting_migrate_range()。它扫描PFN范围并寻
找可以迁移的页面。迁移是将页面复制到系统其它内存部分并更新相关引用的过程。前一
部份很直接，后面的部分需要内存管理子系统来完成。当数据迁移完成，旧的页面被释放
并回归伙伴系统。这就是为什么之前那些需要包含的页面块一定要标记为 
MIGRATE_ISOLATE 的原因。如果指定了其它的迁移类型，伙伴系统会毫不犹豫地将它们用
于其它类型的申请。

现在所有 alloc_contig_range 关心的页都（希望如此）是空闲的了。该方法将从伙伴系
统中取出它们，并将这些页面块的类型改为MIGRATE_CMA。然后将这些页返回给调用者。
释放内存就更简单了。dma_release_from_contiguous() 将其工作转交给：

{% highlight ruby %}
void free_contig_range(unsigned long pfn, unsigned nr_pages);
{% endhighlight %}

这个函数迭代所有的页面并将其返还给伙伴系统。

------------------------------------------------

# Kernel 中使用 CMA

在驱动开发过程中，需要根据特定的需求将 CMA 内存分配给用户空间的程序使用，所有
本节主要讲解如何编写一个 CMA 驱动给用户空间使用。为了在 Kernel 里编写 CMA 驱
动，需要提供一下几种内容：

> 1. CMA 驱动
> 
> 2. CMA 在 DTS 中描述
>
> 3. 内核宏
>
> 4. CMA 配置参数


完整 Github 源码及手册：

{% highlight ruby %}
https://github.com/BiscuitOS/HardStack/blob/master/bus/cma
{% endhighlight %}

## CMA 驱动

CMA 驱动可以参考如下：

{% highlight ruby %}
/*
* CMA driver
*
* (C) 2018.11.29 BiscuitOS <buddy.zhang@aliyun.com>
*
* This program is free software; you can redistribute it and/or modify
* it under the terms of the GNU General Public License version 2 as
* published by the Free Software Foundation.
*/
#include <linux/miscdevice.h>
#include <linux/platform_device.h>
#include <linux/fs.h>
#include <linux/file.h>
#include <linux/mm.h>
#include <linux/list.h>
#include <linux/mutex.h>
#include <linux/debugfs.h>
#include <linux/mempolicy.h>
#include <linux/sched.h>
#include <linux/module.h>
#include <asm/io.h>
#include <asm/uaccess.h>
#include <asm/cacheflush.h>
#include <linux/dma-mapping.h>
#include <linux/export.h>
#include <linux/gfp.h>
#include <linux/acpi.h>
#include <linux/bootmem.h>
#include <linux/cache.h>
#include <linux/export.h>
#include <linux/slab.h>
#include <linux/genalloc.h>
#include <linux/dma-mapping.h>
#include <linux/dma-contiguous.h>
#include <linux/cma.h>
#include <asm/io.h>

#define CMA_MEM_VERSION         3
#define DEVICE_NAME             "CMA"
#define CMEM_IOCTL_MAGIC        'm'
#define CMEM_ALLOCATE           _IOW(CMEM_IOCTL_MAGIC, 1, unsigned int)
#define CMEM_RELEASE            _IOW(CMEM_IOCTL_MAGIC, 2, unsigned int)

struct cmamem_info {
    unsigned int version;
    unsigned int len;
    unsigned int offset;
    unsigned long mem_base;
    unsigned long phy_base;
};

struct cmamem_dev {
    struct miscdevice dev;
    struct mutex cmamem_lock;
    struct list_head info_list;
};

struct current_status {
    int status;
    dma_addr_t phy_base;
};

enum cma_status {
    UNKNOW_STATUS = 0,
    HAVE_ALLOCED = 1,
};

static struct current_status cmamem_status;
static struct cmamem_dev cmamem_dev;
static struct cmamem_info cma_info;

static long cmamem_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
{
    unsigned long nr_pages;
    struct page *page;
    unsigned int pool_size_order;

    switch (cmd) {
    case CMEM_ALLOCATE:
        mutex_lock(&cmamem_dev.cmamem_lock);
        if(cmamem_status.status != HAVE_ALLOCED) {              
            if (copy_from_user(&cma_info, (void __user *)arg,
                                         sizeof(struct cmamem_info))) {
                printk(KERN_ERR "CMEM_ALLOCATE: copy_from_user error\n");
                goto CMA_FAIL;
            }
            if(cma_info.version != CMA_MEM_VERSION) {
                printk(KERN_ERR "CMEM_ALLOCATE: kernel module version "
                              "check fail, version % d\n", cma_info.version);
                goto CMA_FAIL;
            }

            nr_pages = cma_info.len >> PAGE_SHIFT;
            pool_size_order = get_order(cma_info.len);
            page = dma_alloc_from_contiguous(NULL, nr_pages,
                                       pool_size_order, GFP_KERNEL);            

            if(!page) {
                printk(KERN_ERR "CMEM_ALLOCATE: dma_alloc_from_contiguous "
                                "fail, len 0x%x\n", cma_info.len);
                goto CMA_FAIL;
            }

            cma_info.mem_base = (dma_addr_t)page_to_virt(page);
            cma_info.phy_base = (dma_addr_t)page_to_phys(page);
            cmamem_status.phy_base = cma_info.phy_base;
            cmamem_status.status = HAVE_ALLOCED;
        }               
        if (copy_to_user((void __user *)arg, &cma_info,
                                     sizeof(struct cmamem_info))) {
            printk(KERN_ERR "CMEM_ALLOCATE: copy_to_user error\n");
            goto CMA_FAIL;
        }
        mutex_unlock(&cmamem_dev.cmamem_lock);
        return 0;
    case CMEM_RELEASE:
        mutex_lock(&cmamem_dev.cmamem_lock);
        if(cmamem_status.status != HAVE_ALLOCED) {
            printk(KERN_ERR "CMEM_RELEASE: %s, not allocted memory\n",
                                    __func__);
            goto CMA_FAIL;
        }
        if (copy_from_user(&cma_info, (void __user *)arg,
                                    sizeof(struct cmamem_info))) {
            printk(KERN_ERR "CMEM_RELEASE: copy_from_user error\n");
            goto CMA_FAIL;
        }               
        if(cma_info.version != CMA_MEM_VERSION) {
            printk(KERN_ERR "CMEM_RELEASE: kernel module version check fail, "
                       "version % d\n", cma_info.version);
            goto CMA_FAIL;
        }               
        if(cma_info.phy_base != cmamem_status.phy_base) {
            printk(KERN_ERR "CMEM_RELEASE: unknown CMA 0x%lx\n",
                     cma_info.phy_base);
            goto CMA_FAIL;
        }
                
        page = phys_to_page(cmamem_status.phy_base);
        nr_pages = cma_info.len >> PAGE_SHIFT;
        dma_release_from_contiguous(NULL, page, nr_pages);
        memset(&cma_info, 0, sizeof(cma_info));
        memset(&cmamem_status, 0, sizeof(cmamem_status));
        mutex_unlock(&cmamem_dev.cmamem_lock);
        return 0;
    default:
        printk(KERN_INFO "cma mem not support command\n");
        return -EFAULT;
    }
CMA_FAIL:
    mutex_unlock(&cmamem_dev.cmamem_lock);
    return -EFAULT;
}

static int cmamem_mmap(struct file *filp, struct vm_area_struct *vma) {
    unsigned long start = vma->vm_start;
    unsigned long size = vma->vm_end - vma->vm_start;
    unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;
    unsigned long page, pos;

    if (cmamem_status.status != HAVE_ALLOCED) {
        printk(KERN_ERR "cmamem_mmap: %s, you should allocted memory "
                             "firstly\n", __func__);
        return -EINVAL;
    }

    pos = (unsigned long) cmamem_status.phy_base + offset;
    page = pos >> PAGE_SHIFT;
    if (remap_pfn_range(vma, start, page, size, PAGE_SHARED))
        return -EAGAIN;

    vma->vm_flags &= ~VM_IO;
    vma->vm_flags |= (VM_DONTEXPAND | VM_DONTDUMP);

    return 0;
}

static struct file_operations dev_fops = {
    .owner = THIS_MODULE,
    .unlocked_ioctl = cmamem_ioctl,
    .mmap = cmamem_mmap,
};

static int __init cmamem_init(void)
{
    mutex_init(&cmamem_dev.cmamem_lock);
    INIT_LIST_HEAD(&cmamem_dev.info_list);
    cmamem_dev.dev.name = DEVICE_NAME;
    cmamem_dev.dev.minor = MISC_DYNAMIC_MINOR;
    cmamem_dev.dev.fops = &dev_fops;

    cmamem_status.status = UNKNOW_STATUS;
    cmamem_status.phy_base = 0;

    return misc_register(&cmamem_dev.dev);
}

static void __exit cmamem_exit(void)
{
    unsigned long nr_pages;
    struct page *page;
        
    printk(KERN_ERR "%s\n", __func__);
    mutex_lock(&cmamem_dev.cmamem_lock);
    if(cmamem_status.status == HAVE_ALLOCED) {
        page = phys_to_page(cma_info.mem_base);         
        nr_pages = cma_info.len >> PAGE_SHIFT;
        dma_release_from_contiguous(NULL, page, nr_pages);
        memset(&cmamem_status, 0, sizeof(cmamem_status));
    }
    mutex_unlock(&cmamem_dev.cmamem_lock);
    misc_deregister(&cmamem_dev.dev);
}

module_init (cmamem_init);
module_exit (cmamem_exit);
MODULE_LICENSE("GPL");
{% endhighlight %}

Makefile

{% highlight ruby %}
obj-m += cma.o

KERNELDIR ?= /lib/modules/$(shell uname -r)/build

PWD       := $(shell pwd)

ROOT := $(dir $(M))
DEMOINCLUDE := -I$(ROOT)../include -I$(ROOT)/include

GCCVERSION = $(shell gcc -dumpversion | sed -e 's/\.\([0-9][0-9]\)/\1/g' -e 's/\.\([0-9]\)/0\1/g' -e 's/^[0-9]\{3,4\}$$/&00/')

GCC49 := $(shell expr $(GCCVERSION) \>= 40900)

all:
        $(MAKE) -C $(KERNELDIR) M=$(PWD) modules

install: all
        $(MAKE) -C $(KERNELDIR) M=$(PWD) modules_install
        depmod -a

clean:
        rm -rf *.o *.o.d *~ core .depend .*.cmd *.ko *.ko.unsigned *.mod.c .tmp_versions *.symvers \
        .cache.mk *.save *.bak Modules.* modules.order Module.markers *.bin

CFLAGS_cma.o := -Wall $(DEMOINCLUDE)

ifeq ($(GCC49),1)
        CFLAGS_cma.o += -Wno-error=date-time
endif

CFLAGS_cma.o := $(DEMOINCLUDE)
{% endhighlight %}

开发者可以将 CMA 驱动源文件加入到自己的项目源码中进程编译，也可以使用上述的 
Makefile 进行外部模块编译。

## CMA 在 DTS 中描述

CMA 在 DTS 中的描述是可选的，开发者也可以不填写。DTS 中的 CMA 描述相当于给 
kernel 传递 CMA 的配置信息，写法如下：

{% highlight ruby %}
reserved-memory {
    #address-cells = <0x1>;
    #size-cells = <0x1>;
    ranges;

    linux,cma {
        compatible = "shared-dma-pool";
        reusable;
        size = <0xc0000000>;
        alignment = <0x2000>;
        linux,cma-default;
    };
};
{% endhighlight %}

更多 CMA 在 DTS 中描述，请参考 

> Documentation/devicetree/bindings/reserved-memory/reserved-memory.txt

## 内核宏

为了要在 Kernel 中使用 CMA，需要打开如下宏，并未全部给全，开发者根据实际开发环
境而定。如下：

{% highlight ruby %}
CONFIG_CMA=y
# CONFIG_CMA_DEBUG is not set
#
# Default contiguous memory area size:
#
CONFIG_CMA_SIZE_MBYTES=8
CONFIG_CMA_SIZE_SEL_MBYTES=y
# CONFIG_CMA_SIZE_SEL_PERCENTAGE is not set
# CONFIG_CMA_SIZE_SEL_MIN is not set
# CONFIG_CMA_SIZE_SEL_MAX is not set
CONFIG_CMA_ALIGNMENT=8
CONFIG_CMA_AREAS=15
# CONFIG_CMA_RESERVE_DEFAULT_AREA is not set
{% endhighlight %}

## CMA 配置参数

CMA 在内核中使用的最后一步就是配置 CMA 大小，配置的方法有三种，分别是：

> 1. DTS 中指定 CMA 大小
>
> 2. cmdline 传递 CMA 大小
>
> 3. 内核配置设置 CMA 大小


具体实现方法如下：

#### DTS 方法

DTS 方式如下：

{% highlight ruby %}
reserved-memory {
    #address-cells = <0x1>;
    #size-cells = <0x1>;
    ranges;

    linux,cma {
        compatible = "shared-dma-pool";
        reusable;
        size = <0xc0000000>;
        alignment = <0x2000>;
        linux,cma-default;
    };
};
{% endhighlight %}

其中 size 指定了 CMA 的大小，alignment 指定了 CMA 对其方式。

#### cmdline 方式

cmdline 可以通过 uboot 传递也可以通过 DTS 传递，其对 CMA 的配置都相同，都是添
加如下配置：

{% highlight ruby %}
cmdline="... cma=125M"
{% endhighlight %}

如何使用 DTS 方式传递 cmdline，可以按如下配置

{% highlight ruby %}
chosen {
    bootargs = "earlycon cma=256M";
};
{% endhighlight %}

#### 内核配置方法

在内核配置中，打开  CONFIG_CMA_SIZE_MBYTES 宏，配置如下：

{% highlight ruby %}
CONFIG_CMA_SIZE_MBYTES=125M
{% endhighlight %}

------------------------------------------

# 用户空间使用 CMA

根据需求，应用程序需要访问 CMA 内存，开发者可以参考如下代码：

{% highlight ruby %}
/*
* CMA application
*
* (C) 2018.11.29 BiscuitOS <buddy.zhang@aliyun.com>
*
* This program is free software; you can redistribute it and/or modify
* it under the terms of the GNU General Public License version 2 as
* published by the Free Software Foundation.
*/
#include <stdio.h>
#include <stdarg.h>
#include <string.h>
#include <errno.h>
#include <stdlib.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <time.h>
#include <sys/mman.h>
#include <unistd.h>
#include <sys/ioctl.h>

#define CMA_MEM_VERSION         3
#define CMEM_IOCTL_MAGIC        'm'
#define CMEM_ALLOCATE           _IOW(CMEM_IOCTL_MAGIC, 1, unsigned int)
#define CMEM_RELEASE            _IOW(CMEM_IOCTL_MAGIC, 2, unsigned int)
struct cmamem_info {
    unsigned int version;
    unsigned int len;
    unsigned int offset;
    unsigned int mem_base;
    unsigned int phy_base;
};
int main()
{
    int cmem_fd;
    void *cmem_base;
    unsigned int size;
    struct cmamem_info region;

    cmem_fd = open("/dev/cma_mem", O_RDWR, 0);
    if (cmem_fd < 0) {
        perror("Can't open /dev/CMA\n");
        return -1;
    }       
    memset(&region, 0x00, sizeof(struct cmamem_info));
    region.version = CMA_MEM_VERSION;
    region.len = 1 << 20;

    if (ioctl(cmem_fd, CMEM_ALLOCATE, &region) < 0) {    
        perror("PMEM_GET_TOTAL_SIZE failed\n");
        return -1;
    }
    size = region.len;
    cmem_base = mmap(0, size, PROT_READ | PROT_WRITE,
                                  MAP_SHARED, cmem_fd, region.phy_base);
    printf("CMA[%d] Phyaddress: %#08x Virtual base: %#08x "
           "Region.len: %#08x Offset: %#08x\n", i,
               (unsigned int)region.phy_base,
               (unsigned int)cmem_base,
               (unsigned int)region.len,
               (unsigned int)region.offset);
    if (cmem_base == MAP_FAILED) {
        cmem_base = 0;
        ioctl(cmem_fd, CMEM_RELEASE, &region)
        close(cmem_fd);
        cmem_fd = -1;
        perror("mmap pmem error!\n");
    }

    close(cmem_fd);
    return 0;
}
{% endhighlight %}

CMA 在用户空间的访问依赖于 /dev/cma_mem 节点，如果开发者发现没有这个节点，可以
在内核中加入上一节中提到的驱动，然后 /dev/CMA 节点就可以使用 CMA 内存了。

------------------------------------------------------

# 超大 CMA 内存分配

在有些应用场景，需要分配超级大的 CMA 内存，比如 1G，2G 或者 3G。对于这样的问
题，开发者可以参考本文进行超级大的 CMA 内存分配。

首先，我们需要对体系的内存分配进行分析，本例子中使用 ARM64 和 4G 物理内存。在
运行的 Linux 中，使用如下命令查看内存布局，如下图：

![Menuconfig1](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/DEV000055.png)

从上图可以看出，ARM64  RAM 的物理内存被分作了两段，范围如下：

{% highlight ruby %}
0x00000000 -- 0x7fefffff : System RAM
0x800000000 -- 0x87fffffff : System RAM
{% endhighlight %}

第一段 System RAM 中包含了内核的代码和内核数据，第二段 System RAM 供系统运行时
使用。根据 CMA 分配策略可知，CMA 会从第一块可用物理内存的顶端开始向下分配连续
的物理内存给 CMA。因此该物理内存布局的情况下，最大 CMA 不超过 1800M。使用命令
查看当前 CMA 的情况（本例中默认设置 CMA 大小为 1700M），如下：

![Menuconfig1](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/DEV000056.png)

通过上面运行的数据可知，CMA 的体积是 1740800 KB, 也就是 1700M。如果在这个物理
内存布局下再增大 CMA 的体积，将会引起内核 panic。

## 解决方案

通过上面的分析可知，如果要增大 CMA 的体积，关键是要让第一块可用物理内存的体积
尽量大，所以解决方案围绕如何增大第一块物理内存体积来解决。第一块可用连续物理内
存大小配置在 DTS 中进行配置，可以参考如下描述进行配置：

{% highlight ruby %}
memory {
    device-type = "memory";
    reg = <0x0 0x0 0x0 0x7ff00000 0x8 0x0 0x0 0x80000000>;
};
{% endhighlight %}

上面的 DTS 描述用于配置物理内存的布局，其中 reg 描述包含两个 cells，也就是两个
数值表示一个 cells，并且 reg 的第一个 cells 表示物理内存的基地址，第二个 
cells 表示物理内存的大小。如上述， reg 总共描述了两块物理内存，第一块物理内存
的基地址由第一个 cells 表示，其值为  <0x0 0x0>, 表示第一块物理内存的起始地址
是 0x0000 0000 0000 0000； 第一块物理内存的大小由第二个 cells 表示，其值
为 <0x0 0x7ff00000>, 表示第一块物理内存的大小是 0x0000 0000 7ff0 0000; 第二块
物理内存的基地址由第三个 cells 表示，其值为 <0x8 0x0>, 表示第二块物理内存的起
始地址是 0x0000 0008 0000 0000; 第二块物理内存的大小由第四个 cells 表示，其值
为 <0x0 0x80000000>, 表示第二块物理内存的大小是 0x0000 0000 8000 0000.

通过上面的分析可知，开发者只要将 reg 的值设置成一个合适的值即可，通过 
cat /proc/iomem 命令可知，0xfd3d0000 物理地址开始的地方分给了特定的 IO 使用，
所以也就意味着第一块连续物理内存的地址最大到 0xFD3D0000。通过分析，开发者可以
第一块物理内存的地址接近于 0xFD3D0000, 但不要接在一起。设置如下：

> 第一块物理内存起始地址为 0x00000000， 大小为 0xF0000000
>
> 第二块物理内存起始地址为 0x800000000, 大小为 0x10000000


所以 DTS 如下：

{% highlight ruby %}
memory {
    device-type = "memory";
    reg = <0x0 0x0 0x0 0xf0000000 0x8 0x0 0x0 0x10000000>;
};
{% endhighlight %}

接着将 CMA 配置为 3000M，开发者可以参考 **CMA 配置参数** 一节

{% highlight ruby %}
chosen {
    bootargs = "earlycon cma=3000M";
};
{% endhighlight %}

最后重新编译内核，系统启动后，CMA 初始化信息如下：

![Menuconfig1](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/DEV000060.png)

运行 cat /proc/iomem 和 cat /proc/meminfo 命令查看 CMA 内容，如下：

![Menuconfig1](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/DEV000057.png)

通过上面的数据可知，第一块物理内存的起始地址为 0x00000000, 大小为 0xF0000000。
第二块物理内存的起始地址为 0x800000000, 大小为 0x1000000。

![Menuconfig1](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/DEV000058.png)

通过运行内存的查看，CMA 内存总共 3072000 KB, 即 3000M。

由此可以看出修改应该正确，接下来开发者可以使用测试软件，实际测试 CMA 内存是否
真实可用。测试软件的逻辑是循环从 CMA 中申请 1M 大小的 CMA 内存，看能否真实申请
到 3000M CMA 内存。测试代码如下：

{% highlight ruby %}
/*
* Request all CMA and doesn't release.
*
* (C) 2018.11.29 BiscuitOS <buddy.zhang@aliyun.com>
*
* This program is free software; you can redistribute it and/or modify
* it under the terms of the GNU General Public License version 2 as
* published by the Free Software Foundation.
*/
#include <stdio.h>
#include <stdarg.h>
#include <string.h>
#include <errno.h>
#include <stdlib.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <time.h>
#include <sys/mman.h>
#include <unistd.h>
#include <sys/ioctl.h>

#define CMA_MEM_VERSION         3
#define CMEM_IOCTL_MAGIC        'm'
#define CMEM_ALLOCATE           _IOW(CMEM_IOCTL_MAGIC, 1, unsigned int)
#define CMEM_RELEASE            _IOW(CMEM_IOCTL_MAGIC, 2, unsigned int)
struct cmamem_info {
    unsigned int version;
    unsigned int len;
    unsigned int offset;
    unsigned int mem_base;
    unsigned int phy_base;
};
int main()
{
    int cmem_fd;
    void *cmem_base;
    unsigned int size;
    struct cmamem_info region;
    int i;

    cmem_fd = open("/dev/cma_mem", O_RDWR, 0);
    if (cmem_fd < 0) {
        perror("Can't open /dev/CMA\n");
        return -1;
    }       
    for (i = 0; i > -1; i++) {
        memset(&region, 0x00, sizeof(struct cmamem_info));
        region.version = CMA_MEM_VERSION;
        region.len = 1 << 20;

        if (ioctl(cmem_fd, CMEM_ALLOCATE, &region) < 0) {        
            perror("PMEM_GET_TOTAL_SIZE failed\n");
            return -1;
        }
        size = region.len;
        cmem_base = mmap(0, size, PROT_READ | PROT_WRITE,
                                      MAP_SHARED, cmem_fd, region.phy_base);
        printf("CMA[%d] Phyaddress: %#08x Virtual base: %#08x "
               "Region.len: %#08x Offset: %#08x\n", i,
                   (unsigned int)region.phy_base,
                   (unsigned int)cmem_base,
                   (unsigned int)region.len,
                   (unsigned int)region.offset);
        if (cmem_base == MAP_FAILED) {
            cmem_base = 0;
            close(cmem_fd);
            cmem_fd = -1;
            perror("mmap pmem error!\n");
        }

    }
                
    close(cmem_fd);
    return 0;
}
{% endhighlight %}

测试结果如下：

![Menuconfig1](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/DEV000059.png)

通过上面测试，实际真实能分配到 3000 M CMA 内存，所以这样修改是可行的。

---------------------------------------------------

# 附录

[CMA 详细分析](https://blog.csdn.net/pillarbuaa/article/details/79206053)






