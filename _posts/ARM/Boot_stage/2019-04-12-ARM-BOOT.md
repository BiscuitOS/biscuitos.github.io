---
layout:             post
title:              "从第一行代码实践/Debugging ARM linux 5.0 内核"
date:               2019-04-12 07:00:30 +0800
categories:         [MMU]
excerpt:            Debugging ARM Linux from first code.
tags:
  - MMU
---

> [GitHub Bootstrap ARM](https://github.com/BiscuitOS/Bootstrap_arm)
>
> Email: BuddyZhang1 <buddy.zhang@aliyun.com>
>
> Info: ARM 32 -- Linux 5.0

# 目录

> - [简介](#简介)
>
> - [实践](#实践)
>
> - [附录](#附录)

--------------------------------------------------------------
<span id="简介"></span>

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/IND00000A.jpg)

# 简介

> - [文章简介](#文章简介)
>
> - [实践原理](#实践原理)
>
> - [实践准备](#实践准备)
>
> - [实践选择](#实践选择)

### <span id="文章简介">文章简介</span>

俗话说的好 “纸上谈兵终觉浅，绝知此事要躬行”，对于 Linux 内核的学习同样适用，各位
开发者是否看遍了各种经典典籍，但还是对 Linux 不能运用自如。不是开发者不努力，而是
学习 Linux 内核的方法不合适。如何让开发者更有效的学习 Linux 内核其实是作者一直
考虑的问题，经过多年的 Linux 内核开发学习经验，写下了这篇文章和各位开发者分享
如何有效的学习 Linux 内核。

内核实践是作者在 Linux 内核学习中最提倡的学习论，即面对一个全新 Linux 原理或问题，
开发者首先应该做的是如何在有限的实践平台上将原理或问题付诸实践，然后从实践中获得对
Linux 原理和问题的自我认知，有了对问题的自我认知之后再回过头来学习问题对应的原理，
此时，再将原理的认知和实践的认知再投入新的实践中，加入对问题的疑问和想法进行更多的
实践，又从中得到新的认知，有了新的认知之后就产生最原始的求知欲。有了求知欲是一件好
事，凭着这股求知欲去知识里寻找真理，最后问题得到解决，开发者也就学会自主学习的能力，
在经过长期习惯的积累，开发者也就掌握了问题解决的原始能力。

说这么多，那么进入本文的正题。操作系统运作的原理可以简单的总结为 CPU 将位于内存中
的指令和数据加载到 CPU 中运行，重复这个动作，一个操作系统就工作起来。那么可以考虑
这么一个问题，开发者手头正好有一个 Linux 5.x 的内核，想在 ARM 上运行，那么只需将
Linux 5.x 的源码编译汇编成对应平台的指令，然后加载到内存，接着 CPU 读取这些指令，
这样 Linux 就在 ARM 上运行起来了，对一个操作系统就是这么简单的原理工作起来的。
那么本文主要想做的事就是，开发者可以从第一行代码开始编写，然后让这行代码编译汇编
之后加载到内存，之后由 ARM CPU 调用执行，再重复刚刚的操作，这样一行一行代码的添加，
Linux 内核就编写和调试出来了。因此，本文就是用于讲解如何从第一行代码开始，如何编写并
调试运行在 ARM 上的 Linux 5.x。

本文适合作为 Linux 5.0 ARM boot 阶段源码实践教程，也适合操作系统从原点实践教程。

### <span id="实践原理">实践原理</span>

Linux 源码采用 Kbuild 进行源码的编译汇编，并链接生成可在对应硬件平台上运行的
二进制文件。Linux 从源码到目标平台运行的过程经历了下图所示的过程：

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/BOOT000000.png)

如上图所示，Linux 源码经过 Kbuild 编译系统的编译、汇编、链接之后在源码目录生成
ELF 目标文件 vmlinux。由于 vmlinux 包含了各种数据段，此时还不能在 ARM 上直接运行，
于是使用 OBJCOPY 工具将不必要的段丢弃之后，生成二进制文件 Image。此时的 Image
是可以在 ARM CPU 上直接运行的，但此时 Image 的体积太大，不利于一些历史原因，所以
将 Image 进行压缩，生成 piggy_data 文件，由于最新的内核支持多种压缩方式，所以抛弃
以前的 piggy.gz 叫法。由于压缩之后的文件不能直接在 ARM CPU 上运行，所以需要将压缩
后的内核想办法在内存中解压并能让 ARM CPU 能正确执行解压之后的内存，这部分功能称为
bootstrap，为了让压缩之后的内核具有 bootstrap 功能，于是将 piggy_data 文件包含到
一个汇编文件 piggy.S 里面，然后将 piggy.S 与 bootstrap 功能的源码进行编译、汇编、
链接生成 ELF 文件 vmlinux，开发者要注意，此处的 vmlinux 和之前提到的 vmlinux 不是
同一个文件。此时 vmlinux 由于包含了很多不必要的数据段，不能在 ARM CPU 上直接运行，
于是采用了之前的办法，使用 OBJCOPY 工具将不必要的段都丢弃，最后生成可以在 ARM CPU
上运行的二进制文件 zImage。在实际工程实践中，会遇到 uImage，这个二进制文件是通过
uboot 提供的工具，将 zImage 的头部做了修改，以便于 uboot 加载，但 uImage 和内核
没有多大的关系，所以这里不做讨论。更多详细的细节，请参考文档：

> [Bootstrap vmlinux]()

什么位置是 Linux 在 ARM CPU 上运行的起点呢，通过上面的分析可以知道，Linux 最终与
zImage 的形式加载到内存上直接运行，这个阶段的主要任务就是将真正的内核解压到指定
位置，在将 ARM CPU 指向真正内核运行。所以 Linux 加载到 ARM CPU 运行的起点就是
vmlinux 的 bootstrap 功能代码，其源码位于 arch/arm/boot/compressed 目录下，因此
本实践教程以此为原点进行讲解。

### <span id="实践准备">实践准备</span>

由于本实践是基于 ARM Linux 5.0，所以开发者还没有搭建源码开发环境，可以参考如下文档：

> [ARM Linux 5.0 内核源码开发环境搭建](https://biscuitos.github.io/blog/Linux-5.0-arm32-Usermanual/)

实践过程中需要用的原理，芯片手册，文档等，请参考如下链接：

> - [ARM Architecture Reference Manual](https://github.com/BiscuitOS/Documentation/blob/master/Datasheet/ARM/ARM_Architecture_Reference_Manual.pdf)
>
> - [ARMv7 Architecture Reference Manual](https://github.com/BiscuitOS/Documentation/blob/master/Datasheet/ARM/ARMv7_architecture_reference_manual.pdf)
>
> - [Vexpress-a9 Reference Manual](https://github.com/BiscuitOS/Documentation/blob/master/Datasheet/ARM/vexpress-a9.pdf)
>
> - [ARM 汇编实践手册](https://biscuitos.github.io/blog/MMU-ARM32-ASM-index/)
>
> - [ARM 汇编指令快速查询](https://biscuitos.github.io/blog/MMU-ARM32-ASM-index/#ARM_INS_LIST)
>
> - [ARM Debugging Usermanual](https://biscuitos.github.io/blog/BOOTASM-debuggingTools/)

### <span id="实践选择">实践选择</span>

本文提供了三种实践策略，开发者需要选择其中一种策略进行实践。

###### 策略一

这个策略主要面向对 boot 阶段 ARM Linux 源码实践的开发者，在这个策略中，提供原始
的源码文件进行实践，开发者无需做其他步骤，直接进入下一个章节。

###### 策略二

这个策略主要是由于 arch/arm/boot/compressed 目录下兼容了很多平台，导致源码臃肿，
作者提供了一个干净的源码，里面只包含实际运行的代码，不包含其他无用代码。需要使用这个
策略的开发者首先获得 ARM linux 5.0 开发环境，之前提过制作方法。然后进入到源码的
arch/arm/boot/ 目录，将原始的 compressed 目录删除，然后使用如下命令：

{% highlight bash %}
cd arch/arm/boot/
rm -rf compressed/

git clone https://github.com/BiscuitOS/Bootstrap_arm.git compressed
{% endhighlight %}

###### 策略三

这个策略比较策底，从第一行代码开始编写。其做法与策略二类似，请参考如下步骤：

{% highlight bash %}
cd arch/arm/boot/
rm -rf compressed/

git clone https://github.com/BiscuitOS/Bootstrap_arm.git compressed
cd compressed
git reset --hard v0.0.1
{% endhighlight %}

--------------------------------------------------------------
<span id="实践"></span>

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/kernel/IND00000G.jpg)

# 实践

> - [最小实践](#最小实践)
>
> - [zImage 重定位之前实践](#zImage 重定位之前实践)

### <span id="最小实践">最小实践</span>

本小节讲解如何进行最小实践。无论采用何种实践策略，接下来的实践内容都适用。做好的前期
准备之后，开发者首先在源码中加入断点，以方便断点调试。源码位于 arch/arm/boot/compressed/head.S

{% highlight bash %}
 AR_CLASS(      .arm    )
start:
                .type   start,#function
                .rept   7
                .endr
                W(b)    1f

1:
ENTRY(BS_debug)
                mov     r1, #90

                .text
{% endhighlight %}

接着根据 BiscuitOS/output/linux-5.0-arm32/README.md 提供的编译说明，按如下命令
编译内核：

{% highlight bash %}
cd BiscuitOS/output/linux-5.0-arm32/linux/linux
make ARCH=arm CROSS_COMPILE=BiscuitOS/output/linux-5.0-arm32/arm-linux-gnueabi/arm-linux-gnueabi/bin/arm-linux-gnueabi- -j4
{% endhighlight %}

编译完毕之后，继续参照 BiscuitOS/output/linux-5.0-arm32/README.md 提供的编译说明，
打开两个新的终端，第一个终端中输入如下命令：

{% highlight bash %}
cd BiscuitOS/output/linux-5.0-arm32
./RunQemuKernel.sh debug
{% endhighlight %}

第二个终端中输入如下命令：

{% highlight bash %}
BiscuitOS/output/linux-5.0-arm32/arm-linux-gnueabi/arm-linux-gnueabi/bin/arm-linux-gnueabi-gdb -x BiscuitOS/output/linux-5.0-arm32/gdb/gdb_zImage
(gdb) b BS_debug
(gdb) c
(gdb) info reg
{% endhighlight %}

实际运行的效果如下：

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/boot/BOOT000000.png)

本实践中，节本调试方法就是这样，在后续的实践中，只介绍实践后的结果，实践过程在此处。

### <span id="zImage 重定位之前实践">zImage 重定位之前实践</span>

zImage 被加载到内存之后开始在内存上运行，其主要任务就是将压缩的内核在指定位置
进行解压，然后将 CPU 的执行权交给真正的内核进行执行。但 zImage 在执行上面的过程
中，会遇到一个问题，zImage 加载到内存执行，需要对本身进行简单的初始化后运行解压缩
程序，但解压后的内核可能会覆盖 zImage 的数据和代码，因此为了避免这个问题，zImage
在解压内核之前需要将自身重定位到一个安全位置，所谓重定位就是将自身完整拷贝到一个新
的地址继续运行。因此这里就涉及两个过程，zImge 加载到内存进行初始化阶段，以及 zImage
从定位之后解压内核阶段，最后是内核真正运行阶段。本节重点分析实践 zImage 重定位
之前这个阶段。

##### zImage 入口函数

zImage 初始化阶段源码位于 arch/arm/boot/compressed/ 目录下。根据之前分析的原理可知，
压缩之后的内核会添加 bootstrap 功能之后生成 vmlinux，再经过 OBJCOPY 工具处理生成
zImage。所以可以通过查看 vmlinux 的链接脚本确定 zImage 的入口地址。 zImage 使用
的链接脚本位于 arch/arm/boot/compressed/vmlinux.lds.S, 具体内容如下：

{% highlight bash %}
ENTRY(_start)
SECTIONS
{
  . = TEXT_START;
  _text = .;

  .text : {
    _start = .;
    *(.start)
    *(.text)
    *(.text.*)
    *(.fixup)
    *(.gnu.warning)
    *(.glue_7t)
    *(.glue_7)
  }
{% endhighlight %}

从链接脚本可以知道 vmlinux 链接过程，使用 ENTRY 关键字指定了 vmlinux 的入口地址，
也就是第一行运行的代码，这里设置为 _start, 从上面可以看出 _start 位于 .text section
的首地址，所以这里链接脚本告诉开发者，vmlinux 运行的第一行代码就是 vmlinux .text
section 的第一行代码。继续查看链接脚本， .text section 的布局是所有目标文件的
.start section 位于 vmlinux .text section 的最前部，所以开发者只需找到目标文件
中函数 .start section 的文件即可。更多链接脚本的学习可以查看下列文档：

> [GNU LD scripts 详细教程](https://biscuitos.github.io/blog/LD/)

查找 arch/arm/boot/compressed/ 目录下，含有 .start section 的源码位于

{% highlight bash %}
arch/arm/boot/compressed$ grep "\.start" * -nR
big-endian.S:9:	.section ".start", #alloc, #execinstr
Binary file head.o matches
head.S:146:		.section ".start", #alloc, #execinstr
head-sa1100.S:14:		.section        ".start", "ax"
head-sharpsl.S:23:		.section        ".start", "ax"
head-xscale.S:11:		.section        ".start", "ax"
{% endhighlight %}

所以该目录下一共有 4 个文件含有 .start section. 接下来就要根据 arch/arm/boot/compressed/Makefile
来确定 .start section 链接先后顺序了。

{% highlight bash %}
HEAD    = head.o

ifeq ($(CONFIG_ARCH_SA1100),y)
OBJS            += head-sa1100.o
endif

ifeq ($(CONFIG_CPU_XSCALE),y)
OBJS            += head-xscale.o
endif

ifeq ($(CONFIG_PXA_SHARPSL_DETECT_MACH_ID),y)
OBJS            += head-sharpsl.o
endif

ifeq ($(CONFIG_CPU_ENDIAN_BE32),y)
ifeq ($(CONFIG_CPU_CP15),y)
OBJS            += big-endian.o
else

$(obj)/vmlinux: $(obj)/vmlinux.lds $(obj)/$(HEAD) $(obj)/piggy.o \
                $(addprefix $(obj)/, $(OBJS)) $(lib1funcs) $(ashldi3) \
                $(bswapsdi2) $(efi-obj-y) FORCE
        @$(check_for_multiple_zreladdr)
        $(call if_changed,ld)
        @$(check_for_bad_syms)
{% endhighlight %}

从 Makefile 编译位置上可以知道，生成 vmlinux 的时候，head.S 最先被链接到 vmlinux
里面，接着是 head-sa1100.o，head-xscale.o， head-sharpsl.o， big-endian.o。
所以 vmlinux .text section 第一个 section 从 head.S 的 .start section 开始。
因此可以推断 zImage 的第一行代码位于 arch/arm/boot/compressed/head.S 里面。接下来
分析 head.S 文件

##### <span id="head.S">head.S</span>

在 head.S 文件中，可以找到 .start section, 源码如下（代码较长，分段解析）：

{% highlight bash %}
                .section ".start", #alloc, #execinstr
/*
 * sort out different calling conventions
 */
                .align
                /*
                 * Always enter in ARM state for CPUs that support the ARM ISA.
                 * As of today (2014) that's exactly the members of the A and R
                 * classes.
                 */
 AR_CLASS(      .arm    )
start:
                .type   start,#function
                .rept   7
                __nop
                .endr
{% endhighlight %}

首先使用 .section 伪指令定义了一个名为 .start 的 section，并定义了 section
的属性是可分配和可执行的，使用 objdump 工具查看其 ELF 信息：

{% highlight bash %}
$objdump -sShxd head.o

head.o:     file format elf32-little
head.o
architecture: UNKNOWN!, flags 0x00000011:
HAS_RELOC, HAS_SYMS
start address 0x00000000

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .text         00000890  00000000  00000000  00000040  2**5
                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE
  1 .data         00000000  00000000  00000000  000008d0  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  2 .bss          00000000  00000000  00000000  000008d0  2**0
                  ALLOC
  3 .start        00000098  00000000  00000000  000008d0  2**2
                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE
  4 .stack        00001000  00000000  00000000  00000968  2**0
                  ALLOC
  5 .debug_line   00000277  00000000  00000000  00000968  2**0
                  CONTENTS, RELOC, READONLY, DEBUGGING
  6 .debug_info   00000092  00000000  00000000  00000bdf  2**0
                  CONTENTS, RELOC, READONLY, DEBUGGING
  7 .debug_abbrev 00000012  00000000  00000000  00000c71  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_aranges 00000028  00000000  00000000  00000c88  2**3
                  CONTENTS, RELOC, READONLY, DEBUGGING
  9 .debug_ranges 00000020  00000000  00000000  00000cb0  2**3
                  CONTENTS, RELOC, READONLY, DEBUGGING
 10 .ARM.attributes 0000001f  00000000  00000000  00000cd0  2**0
                  CONTENTS, READONLY
{% endhighlight %}

从上面的运行结果可以看出，.start section 的属性为 CONTENTS, ALLOC, LOAD, RELOC,
READONLY, CODE，这些属性正好符合定义时的属性，这正好是一个代码段该有的属性。

接着使用了 .align 伪指令和 .arm 伪指令告诉汇编器，这是一个使用 arm32 指令集并
要求对齐的 section。创建第一个标号 start，开发者可以使用 GDB 工具在 start 处
打断点进行调试。紧接着调用 .type 伪指令告诉汇编器，start 这个标号的类型是一个
#function，也就是 start 标号是一个函数类型。.rept 伪指令和 .endr 伪指令配合
使用，告诉汇编器，这里需要循环 7 次，每次都执行 .rept 伪指令和 .endr 伪指令
之间的代码，这里对应的代码就是 __nop 宏，实现了 7 次等待动作。__nop 宏定义如下：

{% highlight bash %}
                .macro  __nop
#ifdef CONFIG_EFI_STUB
                @ This is almost but not quite a NOP, since it does clobber the
                @ condition flags. But it is the best we can do for EFI, since
                @ PE/COFF expects the magic string "MZ" at offset 0, while the
                @ ARM/Linux boot protocol expects an executable instruction
                @ there.
                .inst   MZ_MAGIC | (0x1310 << 16)       @ tstne r0, #0x4d000
#else
 AR_CLASS(      mov     r0, r0          )
  M_CLASS(      nop.w                   )
#endif
                .endm
{% endhighlight %}

由于本实践过程没有考虑 CONFIG_ELF_STUB 对应的内容，所以调用 .marco 伪指令和
.endm 伪指令定义了 __nop 宏的过程是 “mov r0, r0”， 也就是无意义的操作，起到延时
的作用。接着继续分析 head.S 里面的代码，内容如下：

{% highlight bash %}
#ifndef CONFIG_THUMB2_KERNEL
                mov     r0, r0
#else
 AR_CLASS(      sub     pc, pc, #3      )       @ A/R: switch to Thumb2 mode
  M_CLASS(      nop.w                   )       @ M: already in Thumb2 mode
                .thumb
#endif
                W(b)    1f

                .word   _magic_sig      @ Magic numbers to help the loader
                .word   _magic_start    @ absolute load/run zImage address
                .word   _magic_end      @ zImage end address
                .word   0x04030201      @ endianness flag
                .word   0x45454545      @ another magic number to indicate
                .word   _magic_table    @ additional data table

                __EFI_HEADER
1:
{% endhighlight %}

这段代码首先判断有没有定义 CONFIG_THUMB2_KERNEL 宏，以此确定内核此时是否支持
Thumb 指令集，由于本实践未打开这个宏，所以不执行对应的功能。代码中，没有打开
CONFIG_THUBM2_KERNEL 宏之后，只调用 "mov r0, r0"，一个空操作，等效于 nop，
接着代码条用 b 指令直接跳转到 1f 标签处继续执行。在 1 标签之前，代码为数据分配
了一些存储空间，这些数据也位于 .start section 内部，由于这个段的属性可知，
这些数据是只读而不可写的。下面来分析这些数据的含义:

> _magic_sig 用于存储 Magic 号，加载时候有用
>
> _magic_start 用于指定 zImage 的加载和运行的绝对地址
>
> _magic_end 用于指定 zImage 的结束地址
>
> 0x04030201 表示字节序标志
>
> 0x45454545 表示另一个 Magic 号
>
> _magic_table 指向附加的数据表
>
> __EFI_HEADER 指向 EFI 头

以上的数据用于 zImage 加载和运行时候使用，其具体的数字是 vmlinux 加载的时候
就决定了，可以通过查看 vmlinux.lds.S 链接脚本查看，部分内容如下：

{% highlight bash %}
  .table : ALIGN(4) {
    _table_start = .;
    LONG(ZIMAGE_MAGIC(2))
    LONG(ZIMAGE_MAGIC(0x5a534c4b))
    LONG(ZIMAGE_MAGIC(__piggy_size_addr - _start))
    LONG(ZIMAGE_MAGIC(_kernel_bss_size))
    LONG(0)
    _table_end = .;
  }

  _magic_sig = ZIMAGE_MAGIC(0x016f2818);
  _magic_start = ZIMAGE_MAGIC(_start);
  _magic_end = ZIMAGE_MAGIC(_edata);
  _magic_table = ZIMAGE_MAGIC(_table_start - _start);
{% endhighlight %}

链接过程中，创建了一个名为 .table section，这个 section 按四个字节对齐，
首先定义了 _table_start 指向 section 的起始地址，然后定义了一个 LONG 变量
存储 ZIMAGE_MAGIC(2) 的值，接着定义了一个 LONG 变量存储 ZIMAGE_MAGIC(0x5a534c4b)
的值；定义一个 LONG 变量用于存储 ZIMAGE_MAGIC(__piggy_size_addr - _start)
的值，也就是 __piggy_size_addr 到 _start 之间的长度；第一个 LONG 变量存储
ZIMAGE_MAGIC(_kernel_bss_size) 的值，也就是内核 .bss section 的值；最后定义了
一个为 0 的 LONG 值，以及定义 _table_end 指向 .table section 的结束地址。
接着在 vmlinux.lds.S 链接脚本中，给 _magic_sig 赋值为 ZIMAGE_MAGIC(0x016f2818);
给 _magic_start 赋值为 ZIMAGE_MAGIC(_start)；给 _magic_end 赋值为
ZIMAGE_MAGIC(_edata)；_magic_table 赋值给了 ZIMAGE_MAGIC(_table_start - _start)，
接着开发者可以使用 GDB 工具实践看看运行时布局,如下：

{% highlight bash %}
(gdb) b BS_debug
Breakpoint 1 at 0x3c: file arch/arm/boot/compressed/head.S, line 181.
(gdb) c
Continuing.

Breakpoint 1, BS_debug () at arch/arm/boot/compressed/head.S:181
181			bl BS_func
(gdb) list
176			.word	_magic_table	@ additional data table
177
178			__EFI_HEADER
179	1:
180	ENTRY(BS_debug)
181			bl BS_func
182	 ARM_BE8(	setend	be		)	@ go BE8 if compiled for BE8
183	 AR_CLASS(	mrs	r9, cpsr	)
184	#ifdef CONFIG_ARM_VIRT_EXT
185			bl	__hyp_stub_install	@ get into SVC mode, reversibly
(gdb) print &_magic_sig
$1 = (<variable (not text or data), no debug info> *) 0x16f2818
(gdb) print &_magic_start
$2 = (<text variable, no debug info> *) 0x0 <_text>
(gdb) print &_magic_end
$3 = (<variable (not text or data), no debug info> *) 0x42ba08 <free_mem_end_ptr>
(gdb) print &_magic_table
$4 = (<variable (not text or data), no debug info> *) 0x3af8
(gdb)
{% endhighlight %}

在使用 objdump 工具查看 vmlinux 的 .text section, 内容如下：

{% highlight bash %}
$ objdump -sShdx vmlinux

Contents of section .text:
 0000 0000a0e1 0000a0e1 0000a0e1 0000a0e1  ................
 0010 0000a0e1 0000a0e1 0000a0e1 0000a0e1  ................
 0020 050000ea 18286f01 00000000 08ba4200  .....(o.......B.
 0030 01020304 45454545 f83a0000 d00d00eb  ....EEEE.:......
 0040 00900fe1 8d0d00eb 0170a0e1 0280a0e1  .........p......
 0050 00200fe1 030012e3 0100001a 1700a0e3  . ..............
 0060 563412ef 00000fe1 1a0020e2 1f0010e3  V4........ .....
 0070 1f00c0e3 d30080e3 0400001a 010c80e3  ................
{% endhighlight %}

从上面的运行分析之后，可以知道，在 .text section 的头部定义了一个 zImage 的
 Magic 头，这个 zImage Magic 头的布局如下：

{% highlight bash %}

+-------------------------------------+ low_addr
|            Magic Number             |
+-------------------------------------+
|         Magic Start Address         |
+-------------------------------------+
|          Magic End Address          |
+-------------------------------------+
|             0x01020304              |
+-------------------------------------+
|             0x45454545              |
+-------------------------------------+
|      Magic Table Base Address       |
+-------------------------------------+
|            __EFI_HEADER             |
+-------------------------------------+ high_addr
{% endhighlight %}

__EFI_HEADER 定义在 elf-header.S 文件中，由于本实践不支持 CONFIG_EFI_STUB 功能，
所以这里不讨论这个部分。接着继续讨论 head.S 文件中内容。

{% highlight bash %}
 ARM_BE8(       setend  be              )       @ go BE8 if compiled for BE8
 AR_CLASS(      mrs     r9, cpsr        )
#ifdef CONFIG_ARM_VIRT_EXT
                bl      __hyp_stub_install      @ get into SVC mode, reversibly
#endif
{% endhighlight %}

由于不支持 ARM_BE8, 所以 "setend be" 指令不被执行，继续执行 "mrs r9, cpsr"
指令，这个指令的作用就是将 CPSR 寄存器的值存储到 R9 寄存器中。接下来检查是否支持
CONFIG_ARM_VIRT_EXT 拓展，本实践平台上支持这个功能，所以接上来调用 "bl __hyp_stub_install"
指令。__hyp_stub_install 函数定义在 hyp-stub.S 文件中，如下：

{% highlight bash %}
/*
 * Hypervisor stub installation functions.
 *
 * These must be called with the MMU and D-cache off.
 * They are not ABI compliant and are only intended to be called from the kernel
 * entry points in head.S.
 */
@ Call this from the primary CPU
ENTRY(__hyp_stub_install)
        store_primary_cpu_mode  r4, r5, r6
ENDPROC(__hyp_stub_install)

        @ fall through...

@ Secondary CPUs should call here
ENTRY(__hyp_stub_install_secondary)



        .macro  store_primary_cpu_mode  reg1:req, reg2:req, reg3:req
        .endm
{% endhighlight %}

从函数的注释可以看出，函数的作用是安装管理程序， __hyp_stub_install 函数内部调用
了 store_primary_cpu_mode 宏，并传入 r4, r5, 和 r6 三个参数，由于
store_primary_cpu_mode 宏的定义里不做任何实际操作，那么 __hyp_stub_install
函数就继续执行 __hyp_stub_install_secondary 函数，函数的源码如下：

{% highlight bash %}
/*
 * The zImage loader only runs on one CPU, so we don't bother with mult-CPU
 * consistency checking:
 */
        .macro  compare_cpu_mode_with_primary mode, reg1, reg2, reg3
        cmp     \mode, \mode
        .endm

@ Secondary CPUs should call here
ENTRY(__hyp_stub_install_secondary)
        mrs     r4, cpsr
        and     r4, r4, #MODE_MASK

        /*
         * If the secondary has booted with a different mode, give up
         * immediately.
         */
        compare_cpu_mode_with_primary   r4, r5, r6, r7
        retne   lr

        /*
         * Once we have given up on one CPU, we do not try to install the
         * stub hypervisor on the remaining ones: because the saved boot mode
         * is modified, it can't compare equal to the CPSR mode field any
         * more.
         *
         * Otherwise...
         */

        cmp     r4, #HYP_MODE
        retne   lr                      @ give up if the CPU is not in HYP mode
{% endhighlight %}

函数首先调用 mrs 指令将 CPSR 寄存器的值存储到 R4 寄存器里，然后调用 and 指令
将 r4 中的值与 MODE_MASK 相与，结果存放在 r4 中，总所周知，CPSR 的第 5 位描述当前
CPU 的模式，如下图：

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/boot/BOOT000001.png)

ARM 所支持的模式定义如下：

{% highlight bash %}
#if defined(__KERNEL__) && defined(CONFIG_CPU_V7M)
/*
 * Use 0 here to get code right that creates a userspace
 * or kernel space thread.
 */
#define USR_MODE        0x00000000
#define SVC_MODE        0x00000000
#else
#define USR_MODE        0x00000010
#define SVC_MODE        0x00000013
#endif
#define FIQ_MODE        0x00000011
#define IRQ_MODE        0x00000012
#define MON_MODE        0x00000016
#define ABT_MODE        0x00000017
#define HYP_MODE        0x0000001a
#define UND_MODE        0x0000001b
#define SYSTEM_MODE     0x0000001f
#define MODE32_BIT      0x00000010
#define MODE_MASK       0x0000001f
{% endhighlight %}

代码中调用 compare_cpu_mode_with_primary 宏对 r4 寄存器进行带优先级的比较
操作，如果比较的结果不等于零那么就直接退出函数；如果等于零，那么就继续执行函数，
从 compare_cpu_mode_with_primary 宏的定义可知，它将 r4 与 r4 寄存器进行对比，
对比的值一定等于 0， 所以函数继续执行，接下来函数调用 cmp 指令，将 r4 的值
与 HYP_MODE 模式进行对比，确定当前模式是否是 HYP_MODE，如果是，那么就继续执行
函数；如果不是，则直接返回。使用 GDB 实际测试结果如下：

{% highlight bash %}
(gdb) b BS_X
Note: breakpoint 1 also set at pc 0x3680.
Breakpoint 2 at 0x3680: file arch/arm/boot/compressed/hyp-stub.S, line 97.
(gdb) c
Continuing.

Breakpoint 1, __hyp_stub_install_secondary ()
    at arch/arm/boot/compressed/hyp-stub.S:97
97		mrs	r4, cpsr
(gdb) n
98		and	r4, r4, #MODE_MASK
(gdb) n
104		compare_cpu_mode_with_primary	r4, r5, r6, r7
(gdb) n
105		retne	lr
(gdb) n
116		cmp	r4, #HYP_MODE
(gdb) info reg
r0             0x0                 0
r1             0x0                 0
r2             0x0                 0
r3             0x0                 0
r4             0x13                19
r5             0x0                 0
r6             0x0                 0
r7             0x0                 0
r8             0x0                 0
{% endhighlight %}

从上面可知，r4 所存储的当前模式不是 HYP 模式，所以放弃进入 HYP 模式。接下来函数
直接返回。接着函数返回之后，函数继续在 head.S 中继续执行如下代码：

{% highlight bash %}
                mov     r7, r1                  @ save architecture ID
                mov     r8, r2                  @ save atags pointer


#ifndef CONFIG_CPU_V7M
                /*
                 * Booting from Angel - need to enter SVC mode and disable
                 * FIQs/IRQs (numeric definitions from angel arm.h source).
                 * We only do this if we were in user mode on entry.
                 */
                mrs     r2, cpsr                @ get current mode
                tst     r2, #3                  @ not user?
                bne     not_angel
                mov     r0, #0x17               @ angel_SWIreason_EnterSVC
 ARM(           swi     0x123456        )       @ angel_SWI_ARM
 THUMB(         svc     0xab            )       @ angel_SWI_THUMB
not_angel:
                safe_svcmode_maskall r0
                msr     spsr_cxsf, r9           @ Save the CPU boot mode in
                                                @ SPSR
#endif
{% endhighlight %}

由于 uboot 结束后，会将 architecture ID 存放在 r7 寄存器，将 uboot 的 ATAG
参数的指针存放在 r8 寄存器里。于是代码中调用 mov 指令将 r7 的值存储到 r1 寄存器里，
将 r8 寄存器的值存储到 r2 寄存器里。由于本实践过程中，CONFIG_CPU_V7M 宏没有打开，
那么继续执行下一条指令是 "mrs r2, cpsr"， 这条指令将 CPSR 寄存器的值存储到 r2 寄存器
内，然后调用 tst 指令将 r2 寄存器的值与立即数 3 相与，如果相与的结果不等于 0， 那么
表示当前 CPU 所处的模式不是 User 模式，那么跳转到 not_angel 标签处继续执行；
如果相与的结果等于零，那么 CPU 处于 User 模式，那么调用 swi 指令直接进入 SVC 模式。
这段代码的主要任务就是如果当前模式是 User 模式，那么从 Angel 启动，在启动之前，
需要进入 SVC 模式，并关闭所有的 FIQs/IRQs 中断。接着调用 safe_svcmode_maskall
宏，接下来分析 safe_svcmode_maskall 宏，代码如下：

{% highlight bash %}
/*
 * Helper macro to enter SVC mode cleanly and mask interrupts. reg is
 * a scratch register for the macro to overwrite.
 *
 * This macro is intended for forcing the CPU into SVC mode at boot time.
 * you cannot return to the original mode.
 */
.macro safe_svcmode_maskall reg:req
#if __LINUX_ARM_ARCH__ >= 6 && !defined(CONFIG_CPU_V7M)
        mrs     \reg , cpsr
        eor     \reg, \reg, #HYP_MODE
        tst     \reg, #MODE_MASK
        bic     \reg , \reg , #MODE_MASK
        orr     \reg , \reg , #PSR_I_BIT | PSR_F_BIT | SVC_MODE
THUMB(  orr     \reg , \reg , #PSR_T_BIT        )
        bne     1f
        orr     \reg, \reg, #PSR_A_BIT
        badr    lr, 2f
        msr     spsr_cxsf, \reg
        __MSR_ELR_HYP(14)
        __ERET
1:      msr     cpsr_c, \reg
2:
#else
/*
 * workaround for possibly broken pre-v6 hardware
 * (akita, Sharp Zaurus C-1000, PXA270-based)
 */
        setmode PSR_F_BIT | PSR_I_BIT | SVC_MODE, \reg
#endif
.endm
{% endhighlight %}

由于本实践内容符合 __LINUX_ARM_ARCH__ 大于 6，而且 CONFIG_CPU_V7M 宏没有
定义，所以宏执行的代码为上部。宏首先执行 "mrs \reg, cpsr" 指令，根据调用宏处可知，
宏将 CPSR 的值存储到 r0 寄存器中，然后将 r0 寄存器的值与 HYP_MODE 宏进行异或
操作，结果存储到 r0 寄存器内，然后调用 tst 指令将 r0 寄存器的值与 MODE_MASK
进行与操作, 最后调用 bic 指令清除掉 MODE_MASK 对应的位，这样 r0 中模式位就全部
清零。接着调用 orr 指令将 (PSR_I_BIT | PSR_F_BIT | SVC_MODE) 的值与 r0 寄存器
的值相与之后存储到 r0 寄存器中。根据 CPSR 寄存器的布局可知：

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/boot/BOOT000001.png)

PSR_I_BIT 对应的是 CPSR 的 I 位，这个位用于 IRQ 的掩码位；PSR_F_BIT 对应的是
CPSR 的 F 位，该位用于 FIQ 的掩码。这两位只要置位，那么对应的中断就断就会被屏蔽。
或上 SVC_MODE 就是将模式设置为 SVC 模式。orr 指令执行的结果不等于零，那么跳转
到 1 标签处，1 标签处调用 "msr cpsr_c, \reg" ，这里 cpsr_c 代表 CPSR 的低
8 位，也就是 CPSR 的控制位。这样 CPU 就进入屏蔽了 IRQ，FRQ 的 SVC 模式。
调用完 safe_svcmode_maskall 之后，head.S 调用 "msr spsr_cxsf, r9" 将 r9
寄存器的值存储到 spsr_cxsf，这里 spsr_cxsf 代表 SPSR 寄存器的 C 域， X 域，
S 域， 和 F 域。由于在设置进入 SVC 模式之前，就将 CPSR 寄存器的值存储到 r9
寄存器，所以 r9 寄存器保存了 CPU 最开始的模式。最后将原始的 CPU 模式存储到了
SPSR 寄存器中。

接下来，head.S 将找到物理地址的起始地址，这个时候 MMU 是没有打开的，这个时候是
忽略任何地址对齐和偏移。head.S 选择最开始的 128MB 处作为对齐地址，然后将
zImage 放在这物理地址起始处，这 128MB 就是用来专门存放 zImage 镜像的。具体
代码如下：

{% highlight bash %}
#ifdef CONFIG_AUTO_ZRELADDR
                /*
                 * Find the start of physical memory.  As we are executing
                 * without the MMU on, we are in the physical address space.
                 * We just need to get rid of any offset by aligning the
                 * address.
                 *
                 * This alignment is a balance between the requirements of
                 * different platforms - we have chosen 128MB to allow
                 * platforms which align the start of their physical memory
                 * to 128MB to use this feature, while allowing the zImage
                 * to be placed within the first 128MB of memory on other
                 * platforms.  Increasing the alignment means we place
                 * stricter alignment requirements on the start of physical
                 * memory, but relaxing it means that we break people who
                 * are already placing their zImage in (eg) the top 64MB
                 * of this range.
                 */
ENTRY(BS_debug)
                mov     r4, pc
                and     r4, r4, #0xf8000000
                /* Determine final kernel image address. */
                add     r4, r4, #TEXT_OFFSET
#else
                ldr     r4, =zreladdr
#endif
{% endhighlight %}

这段代码主要用于计算内核的解压地址，并将解压地址存储到 r4 寄存器中。
首先调用代码 "mov, r4, pc"，将当前 CPU 执行的地址存储到 r4 ，然后在将 0xf8000000
的值与 r4 相与达到对齐的作用，确保之后的内核解压地址按 128M 对齐，然后将 r4 寄存器的
值加上 TEXT_OFFSET，TEXT_OFFSET 代表内核的解压地址，这样 r4 寄存器就存储了内核的解压
地址。TEXT_OFFSET 定义在 arch/arm/Makefile 中，如下：

{% highlight bash %}
# Text offset. This list is sorted numerically by address in order to
# provide a means to avoid/resolve conflicts in multi-arch kernels.
textofs-y       := 0x00008000


# The byte offset of the kernel image in RAM from the start of RAM.
TEXT_OFFSET := $(textofs-y)
{% endhighlight %}

运行到这里插一个 gdb 的内容，由于本实践运行在 qemu 上，并且 gdb 进行调试的时候，使用
了如下默认命令：

{% highlight bash %}
# Debug zImage before reload zImage
#
# (C) 2019.04.11 BuddyZhang1 <buddy.zhang@aliyun.com>
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License version 2 as
# published by the Free Software Foundation.

# Remote to gdb
#
target remote :1234

# Reload vmlinux for zImage
#
add-symbol-file BiscuitOS/output/linux-5.0-arm32/linux/linux/arch/arm/boot/compressed/vmlinux 0x60010000
{% endhighlight %}

上面的命令就会让 zImage 运行的起始地址是 0x60010000, 所以此时使用 GDB 调试的情况
如下：

{% highlight bash %}
(gdb) b BS_debug
Breakpoint 1 at 0x60010094: file arch/arm/boot/compressed/head.S, line 96.
(gdb) c
Continuing.

Breakpoint 1, BS_debug () at arch/arm/boot/compressed/head.S:96
96			mov	r4, pc
(gdb) info reg
r0             0x1d3               467
r1             0x8e0               2272
pc             0x60010094          0x60010094 <BS_debug>
(gdb) n
97			and 	r4, r4, #0xf8000000
(gdb) n
99			add	r4, r4, #TEXT_OFFSET
(gdb) n
108			mov	r0, pc
(gdb) info reg
r0             0x1d3               467
r1             0x8e0               2272
r2             0x800001d3          -2147483181
r3             0x0                 0
r4             0x60008000          1610645504
r5             0x0                 0
pc             0x600100a0          0x600100a0 <BS_debug+12>
cpsr           0x1d3               467
{% endhighlight %}

从上面的运行可知，通过计算，内核解压地址是 0x60008000. 接着执行如下代码：

{% highlight bash %}
                /*
                 * Set up a page table only if it won't overwrite ourself.
                 * That means r4 < pc || r4 - 16k page directory > &_end.
                 * Given that r4 > &_end is most unfrequent, we add a rough
                 * additional 1MB of room for a possible appended DTB.
                 */
ENTRY(BS_debug)
                mov     r0, pc
                cmp     r0, r4
                ldrcc   r0, LC0+32
                addcc   r0, r0, pc
                cmpcc   r4, r0
                orrcc   r4, r4, #1              @ remember we skipped cache_on
                blcs    cache_on
{% endhighlight %}

这段代码的主要任务就是确认 zImage 自己建立的页表会不会被 zImage 镜像的重定位
给覆盖掉。从原理可以知道，zImage 被加载到内存运行之后，会将自己重定位到新的物理地址
运行，这就会出现要创建的页表可能被 zImage 重定位之后覆盖。zImage 镜像如果不被自己给
覆盖，需要满足两个条件中的任意一个：

> r4 < PC

这种情况下，内核的解压地址小于当前 PC 运行物理地址。

> r4 - 16k page directory > &_end

这种情况下，内核的解压地址大于 zImage 结束地址之后的 16KB。一般情况下解压内核
的地址大于 zImage 的结束地址是不太寻常的。这种情况下需要添加 1MB 的空间与链接在
zImage 中的 DTB 隔开。

运行到这里，首先获得 PC 寄存器的值，然后调用 "cmp r0, r4", 从之前的代码可知，
r4 寄存器存储着解压内核的地址，这里执行这条命令的含义是，如果 r0 > r4，那么代表当前
PC 执行地址大于内核解压地址，这种情况符合之前的讨论，所以那么就执行 cache_on 宏；
如果 r0 < r4, 那么 zImage 的运行范围包含了要解压内核的地址，因此需要继续进行检测。
这里执行命令 "ldrcc r0, LC0+32", 通过这个命令，将 LC0 偏移 32 个字节地址对应的内容
拷贝到 r0 寄存器。从后面的讨论可以知道，"LC0+32" 处对应的内容是 zImage 需要重定位
的长度再加上 "16K + 1M" 的长度。这里再加上 PC 的值，确保当前运行的代码也不会被覆盖。
接着执行命令 "cmpcc r4, r0", 重新确定解压内核的物理地址与 zImage 重定位的物理地址
是否存在重叠。如果存在，那么将 r4 寄存器的值加 1，以此标记 cache_on 被跳过；否则
执行 "blcs cache_on" 打开缓存。开发者们可以通过实际 GDB 调试代码可验证。

{% highlight bash %}
(gdb) b BS_debug
Breakpoint 1 at 0x600100a0: file arch/arm/boot/compressed/head.S, line 108.
(gdb) c
Continuing.

Breakpoint 1, BS_debug () at arch/arm/boot/compressed/head.S:108
108			mov	r0, pc
(gdb) n
109			cmp	r0, r4
(gdb) info reg
r0             0x600101d3          467
r1             0x8e0               2272
r2             0x800001d3          -2147483181
r3             0x0                 0
r4             0x60008000          1610645504
Quit
(gdb) n
110			ldrcc	r0, LC0+32
(gdb) n
111			addcc	r0, r0, pc
(gdb) n
112			cmpcc	r4, r0
(gdb) n
113			orrcc	r4, r4, #1		@ remember we skipped cache_on
(gdb) n
114			blcs	cache_on
(gdb) n
cache_on () at arch/arm/boot/compressed/head.S:148
148			mov	r3, #8			@ cache_on function
(gdb)
{% endhighlight %}

从上面的运行结果可以看出，进行第一次 cmp 的时候，r0 中的地址是大于 r4 寄存器中
地址，那么接下来带 cc 条件的指令都不执行，那么代码就直接跳转到 cache_on 代码继续
执行。接下来的代码如下：

{% highlight bash %}
/*
 * Turn on the cache. We need to setup some page table so that we
 * can have both the I and D cache on.
 *
 * We place the page tables 16k down from the kernel execution address,
 * and we hope that nothing else is using it. If we're using it, we
 * will go pop!
 *
 * On entry,
 *   r4 = kernel execution address
 *   r7 = architecture number
 *   r8 = atags pointer
 * On exit,
 *   r0, r1, r2, r3, r9, r10, r12 corrupted
 * This routine must preserve:
 *   r4, r7, r8
 */
                .align  5
cache_on:
                mov     r3, #8                  @ cache_on function
                b       call_cache_fn
{% endhighlight %}

cache_on 用于打开 ARM 的 cache 功能，cache 包括 I-Cache (指令 cache) 和 D-cache
(数据 cache)。为了正常使用 cache，需要建立一个页表供 MMU 使用。zImage 会将这个页表
放在真正内核开始执行地址之前的 16K 位置，希望这个地址不要被非法使用。在执行 cache_on 之前，
r4 寄存器里存储值内核解压地址，这个地址也被成为正真内核开始执行的地址。r7 寄存器存储这体系
相关的数据；r8 寄存器存储着 uboot 传递给内核 ATAG 参数的地址。cache_on 使用伪指令 .align
指定了对齐方式为 5 字节对齐。由于 ARM 将所有家族芯片关于 cache 的操作都放在一个表里维护，
因此 armv7 的 cache 操作也在这个表内，并且 cache_on 操作在表中的偏移是 8，因此代码
将立即数 8 存储到 r3 寄存器，并跳转到 call_cache_fn 出执行，代码如下：

{% highlight bash %}
#define PROC_ENTRY_SIZE (4*5)
/*
 * Here follow the relocatable cache support functions for the
 * various processors. This is a generic hook for locating an
 * entry and jumping to an instruction at the specified offset
 * from the start of the block. Please not this is all position
 * independent code.
 *
 *  r1  = corrupted
 *  r2  = corrupted
 *  r3  = block offset
 *  r9  = corrupted
 *  r12 = corrupted
 */
call_cache_fn:  adr     r12, proc_types
#ifdef CONFIG_CPU_CP15
                mrc     p15, 0, r9, c0, c0      @ get processor ID
#endif
1:              ldr     r1, [r12, #0]           @ get value
                ldr     r2, [r12, #4]           @ get mask
                eor     r1, r1, r9              @ (real ^ mask)
                tst     r1, r2                  @       & mask
 ARM(           addeq   pc, r12, r3             ) @ call cache function
                add     r12, r12, #PROC_ENTRY_SIZE
                b       1b
{% endhighlight %}

本段代码的主要任务就是 cache_on 表中找到 armv7 对应的 cache_on 操作。代码首先使用 adr
伪指令获得 proc_types 的地址，然后在 CONFIG_CPU_CPU15 宏启用的情况下，armv7 这个宏启用，
使用 mrc 指令，读取了 CPU ID 寄存器，寄存器布局如下：

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/boot/BOOT000007.png)

将 ID 相关的信息存储在 r9 寄存器里，然后使用 ldr 指令，从 proc_types 表里按顺序取出每个
成员的第一个值和第二个值，分别存储在 r1, r2 寄存器中。接着代码将 r1 寄存器的值与 r9 寄存器
的值做异或运算，然后将结果存储到 r1 寄存器，接着再调用 tst 命令，将 r1 寄存器与 r2 寄存器
按位与操作。如果结果为零，那么就执行 addeq 指令，将 pc 指向表中的位置；如果结果不为零，
那么调用 add 指令，将 r12 指向下一个表成员，调用 b 指令继续循环。开发者可以在此段代码中
加入适当的断点进行 GDB 调试，调试情况下：

{% highlight bash %}
(gdb) b BS_debug
Breakpoint 1 at 0x600100d8: file arch/arm/boot/compressed/head.S, line 166.
(gdb) c
Continuing.

Breakpoint 1, BS_debug () at arch/arm/boot/compressed/head.S:166
166			eor	r1, r1, r9		@ (real ^ mask)
(gdb) info reg r1
r1             0xf0000             983040
(gdb) info reg r2
r2             0xf0000             983040
(gdb) info reg r9
r9             0x410fc090          1091551376
(gdb) n
167			tst	r1, r2			@ 	& mask
(gdb) info reg r1
r1             0x4100c090          1090568336
(gdb) n
168	 ARM(		addeq	pc, r12, r3		) @ call cache function
(gdb) info reg r1
r1             0x4100c090          1090568336
(gdb) info reg cpsr
cpsr           0x600001d3          1610613203
(gdb) info reg pc
pc             0x600100e0          0x600100e0 <BS_debug+8>
(gdb) n
proc_types () at arch/arm/boot/compressed/head.S:191
191			W(b)	__armv7_mmu_cache_on
(gdb)
{% endhighlight %}

从调试结果可以看出，从 ID 寄存器读出的值是 0x410fc090, 经过 r1 0xf000 异或运算之后，
其值是 4100c090, 然后再通过与 r2 f0000 进行按位与运算之后，结果为 0， 那么找到了需要
的 cache_on 入口，这是将入口地址存入 pc 寄存器中，代码跳转到对应的地址，这里可以看一下
表成员的内容如下：

{% highlight bash %}
/*
 * Table for cache operations. This is basically:
 *   - CPU ID match
 *   - CPU ID mask
 *   - 'cache on' method instruction
 *   - 'cache off' method instruction
 *   - 'cache flush' method instruction
 *
 * We match an entry using: ((real_id ^ match) & mask) == 0
 *
 * Writethrough caches generally only need 'on' and 'off'
 * methods. Writeback caches _must_ have the flush method
 * defined.
 */
                .align  2
                .type   proc_types,#object
proc_types:
                .word   0x000f0000              @ new CPU Id
                .word   0x000f0000
                W(b)    __armv7_mmu_cache_on
                W(b)    __armv7_mmu_cache_off
                W(b)    __armv7_mmu_cache_flush

                .word   0                       @ unrecognised type
                .word   0
                mov     pc, lr
                mov     pc, lr
                mov     pc, lr

                .size   proc_types, . - proc_types

                /*
                 * If you get a "non-constant expression in ".if" statement"
                 * error from the assembler on this line, check that you have
                 * not accidentally written a "b" instruction where you should
                 * have written W(b).
                 */
                .if (. - proc_types) % PROC_ENTRY_SIZE != 0
                .error "This size of one or more proc_types entries is wrong."
                .endif
{% endhighlight %}

表 proc_types 定义为一个 object 对象，其中包含了 armv7 对应的成员，cache_on 对应的入口
函数就是： __armv7_mmu_cache_on, 接下来继续分析 __armv7_mmu_cache_on 函数：

{% highlight bash %}
__armv7_mmu_cache_on:
                mov     r12, lr
#ifdef CONFIG_MMU
                mrc     p15, 0, r11, c0, c1, 4  @ read ID_MMFR0
                tst     r11, #0xf               @ VMSA
                movne   r6, #CB_BITS | 0x2      @ !XN
                blne    __setup_mmu
#endif
{% endhighlight %}

__armv7_mmu_cache_on 函数首先将 lr 寄存器的值存储到 r12 寄存器，然后判断 CONFIG_MMU
宏是否启用。在 armv7 里，这个宏是启用的，所以执行宏限定的代码。首先也是通过 mrc 指令读取
ID_MMFR0 寄存器的值到 r11 寄存器中，ID_MMFR0 寄存器如下：

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/boot/BOOT000007.png)

其中， ID_MMFR0 的最低位用于指示当前 CPU 是支持 VMSA 还是 PMSA。VMSA 指的是 Virtual
Memory System Architecture。PMSA 指的是 Protected Memory System Architecture。
两种模式具有不同的内存管理策略，具体介绍开发者可以参考 ARMv7 Reference Manual。接着使用
tst 指令查看 r11 寄存器的最低 4 位的值，以此判断目前 CPU 是 VMSA 模式还是 PMSA 模式。
如果 r11 寄存器的最低 4 bit 不为零，即 CPU 支持 VMSA 模式，那么代码继续执行带 ne 条件
的指令，这里可以加上适当的断点，然后使用 GDB 进行调试，调试结果如下：

{% highlight bash %}
(gdb) b BS_debug
Breakpoint 1 at 0x600100c4: file arch/arm/boot/compressed/head.S, line 130.
(gdb) c
Continuing.

Breakpoint 1, BS_debug () at arch/arm/boot/compressed/head.S:130
130			mrc	p15, 0, r11, c0, c1, 4	@ read ID_MMFR0
(gdb) n
131			tst	r11, #0xf		@ VMSA
(gdb) n
132			movne	r6, #CB_BITS | 0x2	@ !XN
(gdb) info reg r11
r11            0x100103            1048835
(gdb) info reg cpsr
cpsr           0x200001d3          536871379
(gdb)
{% endhighlight %}

从上面的实践结果可以看出，目前 CPU 支持 VMSA，所以将 CB_BITS 或上 0x2 的值存储到 r6
寄存器，并将跳转到 __setup_mmu 继续执行，代码如下：

{% highlight bash %}
__setup_mmu:    sub     r3, r4, #16384          @ Page directory size
                bic     r3, r3, #0xff           @ Align the pointer
                bic     r3, r3, #0x3f00
{% endhighlight %}

__setup_mmu 的主要功能是建立一个临时页表，并打开 MMU，以此供解压程序使用虚拟地址。正如
上面的代码所示，此时 r4 寄存器指向真正内核运行的起始地址，那么就在这个地址前 16K 处开始
建立页表，将页表的起始地址存储到 r3 寄存器，并使用 bic 指令对 r3 的地址做对齐。开发者
可以在上面适当的位置加上断点，使用 GDB 进行调试，调试情况如下：

{% highlight bash %}
(gdb) b BS_debug
Breakpoint 1 at 0x600100c0: file arch/arm/boot/compressed/head.S, line 125.
(gdb) c
Continuing.

Breakpoint 1, BS_debug () at arch/arm/boot/compressed/head.S:125
125			bic	r3, r3, #0xff		@ Align the pointer
(gdb) n
126			bic	r3, r3, #0x3f00
(gdb) info reg r3
r3             0x60004000          1610629120
(gdb) n
132			mov	r0, r3
(gdb) info reg r3
r3             0x60004000          1610629120
(gdb) info reg r4
r4             0x60008000          1610645504
(gdb)
{% endhighlight %}

从上面的调试情况可以知道，内核运行的地址是 0x60008000, 页表的地址就是 0x60004000,此时
内存的布局如下：

![MMU](https://raw.githubusercontent.com/EmulateSpace/PictureSet/master/BiscuitOS/boot/BOOT000011.png)

继续执行下面代码：

{% highlight bash %}
/*
 * Initialise the page tables, turning on the cacheable and bufferable
 * bits for the RAM area only.
 */
                mov     r0, r3
                mov     r9, r0, lsr #18
                mov     r9, r9, lsl #18         @ start of RAM
                add     r10, r9, #0x10000000    @ a reasonable RAM size
                mov     r1, #0x12               @ XN|U + section mapping
                orr     r1, r1, #3 << 10        @ AP=11
                add     r2, r3, #16384
{% endhighlight %}

代码首先将 r3 寄存器的值存储到 r0 寄存器，并通过对 r0 寄存器按 (1<<18) 对齐，获得 RAM
的起始地址，然后假设 RAM 的长度大概是 256M，并将 RAM 结束地址存放在 r10 寄存器中。这里
这样做的目的是：该阶段，内核采用一个临时页表，页表按 1:1 映射物理地址与虚拟地址，通过计算
获得 RAM 的长度，以此对能真实映射 RAM 的页表项设置一种标志集；同理对不能映射物理地址的页表
项设置另外一种标志集。接着将 0x12 的值和 (3 << 10) 值存储到 r1 寄存器中。将 r3 寄存器
的值加上 16K 存放到 r2 寄存器，主要是为了防止写页表时越界。在适当的位置加上断点，使用 GDB
调试，情况如下：

{% highlight bash %}
(gdb) b BS_debug
Breakpoint 1 at 0x600100c8: file arch/arm/boot/compressed/head.S, line 132.
(gdb) c
Continuing.

Breakpoint 1, BS_debug () at arch/arm/boot/compressed/head.S:132
132			mov	r0, r3
(gdb) n
133			mov	r9, r0, lsr #18
(gdb) n
134			mov	r9, r9, lsl #18		@ start of RAM
(gdb) info reg r9
r9             0x1800              6144
(gdb) n
135			add	r10, r9, #0x10000000	@ a reasonable RAM size
(gdb) info reg r9
r9             0x60000000          1610612736
(gdb) info reg r0
r0             0x60004000          1610629120
(gdb) n
136			mov	r1, #0x12		@ XN|U + section mapping
(gdb) info reg r10
r10            0x70000000          1879048192
(gdb) n
137			orr	r1, r1, #3 << 10	@ AP=11
(gdb) info reg r1
r1             0x12                18
(gdb) n
138			add	r2, r3, #16384
(gdb) info reg r1
r1             0xc12               3090
(gdb) n
139	1:		cmp	r1, r9			@ if virt > start of RAM
(gdb) info reg r2
r2             0x60008000          1610645504
(gdb) info reg r3
r3             0x60004000          1610629120
(gdb)
{% endhighlight %}

从上面的调试结果可以看出 RAM 的起始地址是 0x60000000, RAM 的结束地址是 0x70000000。
页表的起始地址是 0x60004000, 页表的结束地址是 0x60008000。继续执行下面代码：

{% highlight bash %}
1:              cmp     r1, r9                  @ if virt > start of RAM
                cmphs   r10, r1                 @   && end of RAM > virt
                bic     r1, r1, #0x1c           @ clear XN|U + C + B
                orrlo   r1, r1, #0x10           @ Set XN|U for non-RAM
                orrhs   r1, r1, r6              @ set RAM section settings
                str     r1, [r0], #4            @ 1:1 mapping
                add     r1, r1, #1048576
                teq     r0, r2
                bne     1b
{% endhighlight %}

这段代码的主要任务就是设置各个页表项。有前面的代码可以知道，r1 存储着虚拟地址，并且从虚拟
地址 0 开始。 r9 寄存器值存储着物理起始地址。首先调用 cmp 指令确定
